@book{aiebook2025,
  address   = {USA},
  author    = {Chip Huyen},
  isbn      = {978-1801819312},
  publisher = {O'Reilly Media},
  title     = {{AI Engineering}},
  year      = {2025}
}

@misc{brown2020languagemodelsfewshotlearners,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.14165}
}

@misc{chen2017readingwikipediaansweropendomain,
  title         = {Reading Wikipedia to Answer Open-Domain Questions},
  author        = {Danqi Chen and Adam Fisch and Jason Weston and Antoine Bordes},
  year          = {2017},
  eprint        = {1704.00051},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1704.00051}
}

@techreport{forrester2022,
  author      = {{Forrester Consulting}},
  title       = {The Crisis of Fractured Organizations: How Teams Can Address Organizational Misalignment \& Achieve More In The Modern Work Environment},
  institution = {Forrester Research, Inc.},
  type        = {Thought Leadership Paper},
  date        = {2022-12},
  note        = {Commissioned by Airtable},
  url         = {https://www.airtable.com/lp/resources/reports/crisis-of-the-fractured-organization}
}

@misc{fourney2024magenticone,
  title         = {Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks},
  author        = {Adam Fourney and Gagan Bansal and Hussein Mozannar and Cheng Tan and Eduardo Salinas and Erkang and Zhu and Friederike Niedtner and Grace Proebsting and Griffin Bassman and Jack Gerrits and Jacob Alber and Peter Chang and Ricky Loynd and Robert West and Victor Dibia and Ahmed Awadallah and Ece Kamar and Rafah Hosn and Saleema Amershi},
  year          = {2024},
  eprint        = {2411.04468},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2411.04468}
}

@misc{hu2023decipher,
  title         = {DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4},
  author        = {Yebowen Hu and Kaiqiang Song and Sangwoo Cho and Xiaoyang Wang and Hassan Foroosh and Fei Liu},
  year          = {2023},
  eprint        = {2305.14702},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.14702}
}

@online{ixdf_personas_2025,
  author = {Rikke Friis Dam and Teo Yu Siang},
  title  = {Personas – A Simple Introduction},
  year   = {2025},
  url    = {https://www.interaction-design.org/literature/article/personas-why-and-how-you-should-use-them?srsltid=AfmBOooAYhlEh0mlGj-G2Ah1HQjFMXz2c1lRuLjGAk-7T5qYeFTLfwXQ#10_steps_to_creating_your_engaging_personas_and_scenarios-6},
  note   = {Accessed: 2025-08-26}
}

@online{ixdf_user_scenarios_2025,
  author = {Interaction Design Foundation},
  title  = {What are User Scenarios?},
  year   = {2025},
  url    = {https://www.interaction-design.org/literature/topics/user-scenarios},
  note   = {Accessed: 2025-08-26}
}

@misc{ke2025demystifyingdomainadaptiveposttrainingfinancial,
  title         = {Demystifying Domain-adaptive Post-training for Financial LLMs},
  author        = {Zixuan Ke and Yifei Ming and Xuan-Phi Nguyen and Caiming Xiong and Shafiq Joty},
  year          = {2025},
  eprint        = {2501.04961},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2501.04961}
}

@misc{krishnan2025aiagentsevolutionarchitecture,
  title         = {AI Agents: Evolution, Architecture, and Real-World Applications},
  author        = {Naveen Krishnan},
  year          = {2025},
  eprint        = {2503.12687},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2503.12687}
}

@online{langchain2025buildAgent,
  title  = {How to Build an Agent},
  author = {{LangChain}},
  year   = {2025},
  month  = jul,
  day    = {9},
  url    = {https://blog.langchain.com/how-to-build-an-agent/},
  note   = {Last Accessed: 2025-08-26}
}

@online{langgraphagmultiagentsystems,
  author = {{LangChain Documentation}},
  title  = {Multi-agent systems},
  year   = {2025},
  url    = {https://langchain-ai.github.io/langgraph/concepts/multi_agent/},
  note   = {Last Accessed: 2025-08-26}
}

@misc{lewis2021retrievalaugmentedgeneration,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.11401}
}

@misc{lu2025bizfinbench,
  title         = {BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs},
  author        = {Guilong Lu and Xuntao Guo and Rongjunchen Zhang and Wenqiao Zhu and Ji Liu},
  year          = {2025},
  eprint        = {2505.19457},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2505.19457}
}

@online{openai2025promptengineering,
  author = {{OpenAI Help Center}},
  title  = {Best practices for prompt engineering with the OpenAI API},
  year   = {2025},
  month  = aug,
  day    = {15},
  url    = {https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api},
  note   = {Last Accessed: 2025-08-26}
}

@misc{sapkota2025aiagentsvsagentic,
  title         = {AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges},
  author        = {Ranjan Sapkota and Konstantinos I. Roumeliotis and Manoj Karkee},
  year          = {2025},
  eprint        = {2505.10468},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  doi           = {https://doi.org/10.1016/j.inffus.2025.103599},
  url           = {https://arxiv.org/abs/2505.10468}
}

@misc{shinn2023reflexion,
  title         = {Reflexion: Language Agents with Verbal Reinforcement Learning},
  author        = {Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
  year          = {2023},
  eprint        = {2303.11366},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2303.11366}
}

@inproceedings{tanabe2024enhancingfinancialdomainadaptation,
  title     = {Enhancing Financial Domain Adaptation of Language Models via Model Augmentation},
  url       = {http://dx.doi.org/10.1109/BigData62323.2024.10825292},
  doi       = {10.1109/bigdata62323.2024.10825292},
  booktitle = {2024 IEEE International Conference on Big Data (BigData)},
  publisher = {IEEE},
  author    = {Tanabe, Kota and Hirano, Masanori and Matoya, Kazuki and Imajo, Kentaro and Sakaji, Hiroki and Noda, Itsuki},
  year      = {2024},
  month     = dec,
  pages     = {6661–6669}
}

@misc{veseli2025positionalbiasesshiftinputs,
  title         = {Positional Biases Shift as Inputs Approach Context Window Limits},
  author        = {Blerta Veseli and Julian Chibane and Mariya Toneva and Alexander Koller},
  year          = {2025},
  eprint        = {2508.07479},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2508.07479}
}

@article{wang2025replacehumanevaluators,
  title     = {Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering},
  volume    = {2},
  issn      = {2994-970X},
  url       = {http://dx.doi.org/10.1145/3728963},
  doi       = {10.1145/3728963},
  number    = {ISSTA},
  journal   = {Proceedings of the ACM on Software Engineering},
  publisher = {Association for Computing Machinery (ACM)},
  author    = {Wang, Ruiqi and Guo, Jiyu and Gao, Cuiyun and Fan, Guodong and Chong, Chun Yong and Xia, Xin},
  year      = {2025},
  month     = jun,
  pages     = {1955–1977}
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2201.11903}
}

@dataset{wideworldimporters2025,
  author = {{Microsoft Corporation}},
  title  = {WideWorldImporters Sample Database},
  year   = {2025},
  url    = {https://learn.microsoft.com/en-us/sql/samples/wide-world-importers-what-is?view=sql-server-ver17},
  note   = {Sample database for Microsoft SQL Server and Azure SQL, retrieved from Microsoft documentation}
}

@misc{yao2023react,
  title         = {ReAct: Synergizing Reasoning and Acting in Language Models},
  author        = {Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
  year          = {2023},
  eprint        = {2210.03629},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.03629}
}

@misc{zhuge2024agentasajudgeevaluateagentsagents,
  title         = {Agent-as-a-Judge: Evaluate Agents with Agents},
  author        = {Mingchen Zhuge and Changsheng Zhao and Dylan Ashley and Wenyi Wang and Dmitrii Khizbullin and Yunyang Xiong and Zechun Liu and Ernie Chang and Raghuraman Krishnamoorthi and Yuandong Tian and Yangyang Shi and Vikas Chandra and Jürgen Schmidhuber},
  year          = {2024},
  eprint        = {2410.10934},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2410.10934}
}

@article{llmcausalreasoning2024,
  author         = {Wang, Lei and Shen, Yiqing},
  title          = {Evaluating Causal Reasoning Capabilities of Large Language Models: A Systematic Analysis Across Three Scenarios},
  journal        = {Electronics},
  volume         = {13},
  year           = {2024},
  number         = {23},
  article-number = {4584},
  url            = {https://www.mdpi.com/2079-9292/13/23/4584},
  issn           = {2079-9292},
  abstract       = {Large language models (LLMs) have shown their capabilities in numerical and logical reasoning, yet their capabilities in higher-order cognitive tasks, particularly causal reasoning, remain less explored. Current research on LLMs in causal reasoning has focused primarily on tasks such as identifying simple cause-effect relationships, answering basic “what-if” questions, and generating plausible causal explanations. However, these models often struggle with complex causal structures, confounding variables, and distinguishing correlation from causation. This work addresses these limitations by systematically evaluating LLMs’ causal reasoning abilities across three representative scenarios, namely analyzing causation from effects, tracing effects back to causes, and assessing the impact of interventions on causal relationships. These scenarios are designed to challenge LLMs beyond simple associative reasoning and test their ability to handle more nuanced causal problems. For each scenario, we construct four paradigms and employ three types of prompt scheme, namely zero-shot prompting, few-shot prompting, and Chain-of-Thought (CoT) prompting in a set of 36 test cases. Our findings reveal that most LLMs encounter challenges in causal cognition across all prompt schemes, which underscore the need to enhance the cognitive reasoning capabilities of LLMs to better support complex causal reasoning tasks. By identifying these limitations, our study contributes to guiding future research and development efforts in improving LLMs’ higher-order reasoning abilities.},
  doi            = {10.3390/electronics13234584}
}
